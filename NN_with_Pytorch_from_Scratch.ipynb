{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Library Loading**"
      ],
      "metadata": {
        "id": "qY2E6Qf2sgYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDwKKzYAoYa6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preparing the Dataset**"
      ],
      "metadata": {
        "id": "8ywWfRlzokIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# import dataset\n",
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# Validate\n",
        "print('X shape:', X.shape)\n",
        "print('y shape:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t9hTFmJof2_",
        "outputId": "67edb8b5-0245-4901-9f04-b7f0954a4722"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1797, 64)\n",
            "y shape: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Splitting the data into train, valid, and test set."
      ],
      "metadata": {
        "id": "XcMwyvjEovSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split train & (valid and test) --> 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    stratify=y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Split valid & test --> 50:50\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    stratify=y_test,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Validate\n",
        "print('X train shape:', X_train.shape)\n",
        "print('y train shape:', y_train.shape)\n",
        "print('X valid shape:', X_valid.shape)\n",
        "print('y valid shape:', y_valid.shape)\n",
        "print('X test shape :', X_test.shape)\n",
        "print('y test shape :', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5FmHVRhorve",
        "outputId": "3368a129-c196-4fda-9470-6bfabb2e5349"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train shape: (1437, 64)\n",
            "y train shape: (1437,)\n",
            "X valid shape: (180, 64)\n",
            "y valid shape: (180,)\n",
            "X test shape : (180, 64)\n",
            "y test shape : (180,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to torch tensor\n",
        "X_train, y_train = torch.tensor(X_train), torch.tensor(y_train)\n",
        "X_valid, y_valid = torch.tensor(X_valid), torch.tensor(y_valid)\n",
        "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "hrq24CXgo6lp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Create a Comparison Function**\n",
        "\n",
        "- Creating a utility function to compare manual gradients to PyTorch gradients.\n",
        "- The function is to check whether the results we calculate from scratch are the same with calculation from PyTorch library."
      ],
      "metadata": {
        "id": "w8EnkSd5o9gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function for comparing gradients\n",
        "def compare_grad(element, manual_grad, torch_node):\n",
        "    \"\"\"comparing manual gradients to PyTorch gradients\"\"\"\n",
        "    # Extract gradients\n",
        "    torch_grad = torch_node.grad\n",
        "\n",
        "    # Exact comparison\n",
        "    exact = torch.all(manual_grad == torch_grad).item()\n",
        "\n",
        "    # Approximate comparison\n",
        "    apprx = torch.allclose(manual_grad, torch_grad)\n",
        "\n",
        "    # Calculate maximum different between manual and torch gradients\n",
        "    max_diff = (\n",
        "        (manual_grad-torch_grad)    # calculate the difference\n",
        "        .abs()                      # then take the absolute value\n",
        "        .max()                      # and find the maximum value of it\n",
        "        .item()\n",
        "    )\n",
        "\n",
        "    # Print\n",
        "    print(f'{element:15s} | exact: {str(exact):5s} | approximate: {str(apprx):5s} | max diff.: {max_diff}')"
      ],
      "metadata": {
        "id": "qxKlsvBdo4Ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Creating the Neural Network using PyTorch**"
      ],
      "metadata": {
        "id": "eNdwwlqNpTxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a neural network to classify the digits.\n",
        "- The architectures are\n",
        "  - Having 64 input dimensions\n",
        "  - Having 2 layers (1 hidden layer and 1 output layer)\n",
        "  - The output layer has 10 neurons (1 neuron for each digits)"
      ],
      "metadata": {
        "id": "Ff0EvguppW-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the size\n",
        "n_in = 64\n",
        "n_hidden = 24\n",
        "n_out = 10"
      ],
      "metadata": {
        "id": "VSJ7eXo3pKUU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Neural Network\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Layer 1 (The hidden layer)\n",
        "W1 = torch.randn((n_in, n_hidden),  generator=g, dtype=torch.float64) * (5/3) / (n_in**0.5)\n",
        "b1 = torch.randn(n_hidden,          generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Layer 2 (The output layer)\n",
        "W2 = torch.randn((n_hidden, n_out), generator=g, dtype=torch.float64) * 0.1\n",
        "b2 = torch.randn(n_out,             generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Get the parameters\n",
        "parameters = [W1, b1, W2, b2]\n",
        "print(sum(param.nelement() for param in parameters))\n",
        "\n",
        "# Activate the grad\n",
        "for param in parameters:\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvYhPIwWpdqU",
        "outputId": "7c48b84d-ebde-429b-f01c-f4bb15ee067c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a single forward pass that we want to calculate its gradients manually."
      ],
      "metadata": {
        "id": "X_d0rZ3zpyMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1_LiahYJt_Ij-zjCE1RcHCEe2jiDxUXI-\">"
      ],
      "metadata": {
        "id": "eLNFPfD9qSzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch learning\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "\n",
        "# Construct a minibatch\n",
        "mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
        "X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
        "\n",
        "# Validating data\n",
        "print('X_batch shape:', X_batch.shape)\n",
        "print('y_batch shape:', y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1i6xWzup5Bv",
        "outputId": "6ae6c26b-3050-4834-bb55-84558ba102bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_batch shape: torch.Size([32, 64])\n",
            "y_batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing a forward pass\n",
        "\n",
        "# The first hidden layer calculation\n",
        "h_pre_act = X_batch @ W1 + b1\n",
        "\n",
        "# Performing a non-linearity calculation (activation function)\n",
        "h = torch.tanh(h_pre_act)\n",
        "\n",
        "# The second and output layer\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# Calculating loss\n",
        "counts = logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1\n",
        "probs = counts * counts_sum_inv\n",
        "log_probs = probs.log()\n",
        "loss = -log_probs[range(n), y_batch].mean()\n",
        "\n",
        "# Performing the backward pass with PyTorch\n",
        "for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "for p in [log_probs, probs, counts_sum_inv, counts_sum, counts,\n",
        "          logits, h, h_pre_act]:\n",
        "    p.retain_grad()\n",
        "\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Yu7iyNp5af",
        "outputId": "1ce15d53-7f6d-4a0d-d70b-a1657c117dcc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3850, dtype=torch.float64, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Performing Backpropagation for `counts`, `counts_sum`, and `counts_sum_inv`**"
      ],
      "metadata": {
        "id": "nGKs8XdduvM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find :\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts_sum_inv}}\n",
        "$$"
      ],
      "metadata": {
        "id": "9I_PBTMCvEWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1ehlVs8Ol9-VILS-ogqaOaS8NLxNIvXcT\">"
      ],
      "metadata": {
        "id": "hz7kMIHsvJpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Calculating the `counst_sum_inv`"
      ],
      "metadata": {
        "id": "4keNEgObvNA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the graph, `counts` derivative is come from `probs` and `counts_sum`\n",
        "- We can find the `counts` derivative step by step, start from the `counts_sum_inv`\n",
        "\n",
        "\n",
        "- We can use the equation :\n",
        "```\n",
        "probs = counts * counts_sum_inv\n",
        "dprobs = counts dcounts_sum_inv\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dcounts_sum_inv = counts * dprobs\n",
        "```"
      ],
      "metadata": {
        "id": "TlD-Tdw4vRBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyfTYw6LvUj7",
        "outputId": "b04a58a2-01f3-4a63-df5c-b629c397a87e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Calculate the `counst_sum`"
      ],
      "metadata": {
        "id": "dBo_aVTivhEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Then we can find the derivative of `loss` to the `counts_sum`\n",
        "\n",
        "- We can use the equation :\n",
        "```\n",
        "counts_sum_inv = counts_sum**-1\n",
        "dcounts_sum_inv = -1 * (counts_sum)**(-2)\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dcounts_sum = counts * dcounts_sum_inv\n",
        "```"
      ],
      "metadata": {
        "id": "FZKslpZDvjyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating dcounts_sum\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMaaBu5gvoEw",
        "outputId": "3e93c82d-e2a1-4065-baee-565e7cc0ca3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Calculate the `counst`"
      ],
      "metadata": {
        "id": "h7ItDorrv4As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Finally, we can calculate the derivative of `loss` to `counts`\n",
        "- Remember, there are two sources of gradient to the `counts` node, i.e. from `probs` and `counts_sum`"
      ],
      "metadata": {
        "id": "tuN94sjLv9Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "probs = counts * counts_sum_inv\n",
        "dprobs = counts_sum_inv * dcounts\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dcounts = counts_sum_inv * dprobs\n",
        "```"
      ],
      "metadata": {
        "id": "IQoZ2y6sv_Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Next, we can use the equation\n",
        "```\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "dcounts_sum = 1. * dcounts\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dcounts = 1. * dcounts_sum\n",
        "```"
      ],
      "metadata": {
        "id": "f0rXNNI7wCf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Rqx63BwGM5",
        "outputId": "57b29dc0-1f6a-4778-9366-d89ec7e43a30"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Performing Backprop the `logits`**"
      ],
      "metadata": {
        "id": "_b82Ga3bwXh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{logits}}\n",
        "$$"
      ],
      "metadata": {
        "id": "1TZsTuwFweZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1v4FqTiXVBT0E5wkF1ZFksYpUm8nijPEQ\">"
      ],
      "metadata": {
        "id": "dPg7a3BDwhTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "counts = exp(logits)\n",
        "dcounts = exp(logits) dlogits\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dlogits = exp(logits) * dcounts\n",
        "```"
      ],
      "metadata": {
        "id": "QupbX09swjW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits = counts * dcounts\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ImbXmLwqll",
        "outputId": "af31cb60-8718-4a1b-9f5f-83f805a63383"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Performing Backpropagation for `W2`, `b2`, and `h`**"
      ],
      "metadata": {
        "id": "UL4kGcgcqajK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here I try to find the parameters for second layer."
      ],
      "metadata": {
        "id": "XDroIYgls5h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find :\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{W2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h}}\n",
        "$$"
      ],
      "metadata": {
        "id": "8k_AYa7ZqgtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1c8c2jyWPyWQC_nqGmk2ifb-hpIWyALKN\">"
      ],
      "metadata": {
        "id": "bKgiOuKDqjgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "logits = h @ W2 + b2\n",
        "dlogits = W2 dh\n",
        "dlogits = 1 db2\n",
        "dlogits = h dW2\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dW2 = h * dlogits\n",
        "dloss/dh = W2 * dlogits\n",
        "dloss/db2 = 1 * dlogits\n",
        "```"
      ],
      "metadata": {
        "id": "DaqDoQkxqmoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In details, let :\n",
        "\n",
        "$$\n",
        "d = h \\cdot w + c\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "d_{11} & d_{12} & d_{13}\\\\\n",
        "d_{21} & d_{22} & d_{23}\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{12}\\\\\n",
        "h_{21} & h_{22}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13}\\\\\n",
        "w_{21} & w_{22} & w_{23}\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "c_{1} & c_{2} & c_{3}\\\\\n",
        "c_{1} & c_{2} & c_{3}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "d_{11} &= h_{11}w_{11} + h_{12}w_{21} + c_{1} \\\\\n",
        "d_{12} &= h_{11}w_{12} + h_{12}w_{22} + c_{2} \\\\\n",
        "d_{13} &= h_{11}w_{13} + h_{12}w_{23} + c_{3} \\\\\n",
        "d_{21} &= h_{21}w_{11} + h_{22}w_{21} + c_{1} \\\\\n",
        "d_{22} &= h_{21}w_{12} + h_{22}w_{22} + c_{2} \\\\\n",
        "d_{23} &= h_{21}w_{13} + h_{22}w_{23} + c_{3} \\\\\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "55DkwXfdqpgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So, we can find the derivative of loss with respect to model parameters."
      ],
      "metadata": {
        "id": "dRBJqjZkqvXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial L}{\\partial w_{11}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{12}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{13}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{21}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot h_{22} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{22}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot h_{22} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{23}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot h_{22}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial w_{11}} & \\cfrac{\\partial L}{\\partial w_{12}} & \\cfrac{\\partial L}{\\partial w_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{21}} & \\cfrac{\\partial L}{\\partial w_{22}} & \\cfrac{\\partial L}{\\partial w_{23}}\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{21}\\\\\n",
        "h_{12} & h_{22}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial d_{11}} & \\cfrac{\\partial L}{\\partial d_{12}} & \\cfrac{\\partial L}{\\partial d_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial d_{21}} & \\cfrac{\\partial L}{\\partial d_{22}} & \\cfrac{\\partial L}{\\partial d_{23}}\n",
        "\\end{bmatrix}\\\\\n",
        "\\cfrac{\\partial L}{\\partial W} &= h^{T} \\cdot \\cfrac{\\partial L}{\\partial d}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "wLbu5hfzqy_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With similar way, we got :\n",
        "\n",
        "$$\n",
        "\\cfrac{\\partial L}{\\partial h} = \\cfrac{\\partial L}{\\partial d} \\cdot W^{T}\n",
        "$$\n",
        "\n",
        "- For the bias :\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial L}{\\partial c_{1}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot 1.0 \\\\\n",
        "\\cfrac{\\partial L}{\\partial c_{2}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot 1.0 \\\\\n",
        "\\cfrac{\\partial L}{\\partial c_{3}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot 1.0 \\\\\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "SiXNBE91q5ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial c_{1}} & \\cfrac{\\partial L}{\\partial c_{2}} & \\cfrac{\\partial L}{\\partial c_{3}}\\\\\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "1.0 & 1.0 & 1.0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial d_{11}} & \\cfrac{\\partial L}{\\partial d_{12}} & \\cfrac{\\partial L}{\\partial d_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial d_{21}} & \\cfrac{\\partial L}{\\partial d_{22}} & \\cfrac{\\partial L}{\\partial d_{23}}\n",
        "\\end{bmatrix}\\\\\n",
        "\\cfrac{\\partial L}{\\partial c} &= \\begin{bmatrix}\n",
        "1.0 & 1.0 & 1.0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\cfrac{\\partial L}{\\partial d}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "fJizY7F5rA1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating backprop for 2nd layer\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)  # add along the columns (neurons)"
      ],
      "metadata": {
        "id": "nwyf7f7UrOb5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJb6jW-lp7yc",
        "outputId": "e598b927-5626-403b-8019-df0db000a1a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Backpropagation the `h_pre_act`**"
      ],
      "metadata": {
        "id": "gQjp9c-IrWCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we try to find the parameter of h before performed with activation function."
      ],
      "metadata": {
        "id": "ZRDlZJEQtJIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h_pre_act}}\n",
        "$$"
      ],
      "metadata": {
        "id": "qU_qhpt1rceE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1zaovirepV51QS0nS9lJVntb85Lf4tZQ_\">"
      ],
      "metadata": {
        "id": "StsGDSt0rfFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation :\n",
        "```\n",
        "h = tanh(h_pre_act)\n",
        "dh = (1 - tanh(h_pre_act)**2) dh_pre_act\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dh_pre_act = (1 - tanh(h_pre_act)**2) * dh\n",
        "```"
      ],
      "metadata": {
        "id": "42N80RUBrgyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating backprop for pre-activation\n",
        "dh_pre_act = (1 - h**2) * dh"
      ],
      "metadata": {
        "id": "lUxG-eUjrQ0p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)\n",
        "compare_grad('h_pre_act', dh_pre_act, h_pre_act)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6d0bzahrj0U",
        "outputId": "839b2352-9dfd-4374-884d-5004e8a6aa51"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h_pre_act       | exact: False | approximate: True  | max diff.: 4.336808689942018e-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Performing Backpropagation for `W1` and `b1`**"
      ],
      "metadata": {
        "id": "7LrcyxNBtvhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we try to calculate the parameters in the first layer."
      ],
      "metadata": {
        "id": "PTyzxFJyt4qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{W1}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{b1}}\n",
        "$$"
      ],
      "metadata": {
        "id": "ZPz4kG5tuBPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1a3NSCtenXUFHU9Z3AA7EEG7GFt1PadMZ\">"
      ],
      "metadata": {
        "id": "a1ry-mY-uEL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation as follow :\n",
        "```\n",
        "h_pre_act = X @ W1 + b1\n",
        "dh_pre_act = X dW1\n",
        "dh_pre_act = 1 b1\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dW1 = X * dh_pre_act\n",
        "dloss/db1 = 1 * dh_pre_act\n",
        "```"
      ],
      "metadata": {
        "id": "CZrwwsItuGAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating backprop in 1st layer\n",
        "dW1 = X_batch.T @ dh_pre_act\n",
        "db1 = dh_pre_act.sum(0)"
      ],
      "metadata": {
        "id": "caY-AexduIa9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)\n",
        "compare_grad('h_pre_act', dh_pre_act, h_pre_act)\n",
        "compare_grad('W1', dW1, W1)\n",
        "compare_grad('b1', db1, b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfZ3e3lCuJ5R",
        "outputId": "e05a82e5-dfe6-4f77-c8cb-7b433db3a149"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h_pre_act       | exact: False | approximate: True  | max diff.: 4.336808689942018e-19\n",
            "W1              | exact: False | approximate: True  | max diff.: 4.163336342344337e-17\n",
            "b1              | exact: False | approximate: True  | max diff.: 1.734723475976807e-18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Train with manual backpropagation**"
      ],
      "metadata": {
        "id": "-OqWe_YTrqxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First, reinitialize the weights"
      ],
      "metadata": {
        "id": "EIFUZGyVruC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Neural Network\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Layer 1 (The hidden layer)\n",
        "W1 = torch.randn((n_in, n_hidden),  generator=g, dtype=torch.float64) * (5/3) / (n_in**0.5)\n",
        "b1 = torch.randn(n_hidden,          generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Layer 2 (The output layer)\n",
        "W2 = torch.randn((n_hidden, n_out), generator=g, dtype=torch.float64) * 0.1\n",
        "b2 = torch.randn(n_out,             generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Get the parameters\n",
        "parameters = [W1, b1, W2, b2]\n",
        "print(sum(param.nelement() for param in parameters))\n",
        "\n",
        "# Activate the grad\n",
        "for param in parameters:\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhQesrqCrxN8",
        "outputId": "d529e042-5b69-45da-b393-202670fb73c0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the NN model"
      ],
      "metadata": {
        "id": "7ieVTGoXrzTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 100_000\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "losses = []\n",
        "\n",
        "# We will calculate the grad manually\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Start optimizing\n",
        "    for i in range(max_steps):\n",
        "        # Construct a minibatch\n",
        "        mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
        "        X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
        "\n",
        "        # Perform the forward pass\n",
        "        h_pre_act = X_batch @ W1 + b1\n",
        "        h = torch.tanh(h_pre_act)\n",
        "        logits = h @ W2 + b2\n",
        "\n",
        "        # Calculate loss\n",
        "        counts = logits.exp()\n",
        "        counts_sum = counts.sum(1, keepdims=True)\n",
        "        counts_sum_inv = counts_sum**-1\n",
        "        probs = counts * counts_sum_inv\n",
        "        log_probs = probs.log()\n",
        "        loss = -log_probs[range(n), y_batch].mean()\n",
        "\n",
        "        # Let's do the backward pass\n",
        "        for p in parameters:\n",
        "            p.grad = None\n",
        "\n",
        "        # Let's manually calculate the gradients\n",
        "        dlog_probs = torch.zeros_like(log_probs)\n",
        "        dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "        dprobs = (1./probs) * dlog_probs\n",
        "        dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "        dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "        dcounts = counts_sum_inv * dprobs\n",
        "        dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "        dlogits = counts * dcounts\n",
        "        dW2 = h.T @ dlogits\n",
        "        dh = dlogits @ W2.T\n",
        "        db2 = dlogits.sum(0)\n",
        "        dh_pre_act = (1 - h**2) * dh\n",
        "        dW1 = X_batch.T @ dh_pre_act\n",
        "        db1 = dh_pre_act.sum(0)\n",
        "        grads = [dW1, db1, dW2, db2]  # store the grads of our model parameters\n",
        "\n",
        "        # Update the model parameters\n",
        "        lr = 0.05 if i < 50_000 else 0.001\n",
        "        for p, grad in zip(parameters, grads):\n",
        "            p.data += -lr * grad\n",
        "\n",
        "        # Track\n",
        "        if i%10000 == 0:\n",
        "            print(f'{i:8d}/{max_steps:8d}: {loss.item():.4f}')\n",
        "        losses.append(loss.log().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieb6xQLmrl6M",
        "outputId": "c6fb10ef-3cac-4469-9d40-6898503fcd85"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0/  100000: 2.3850\n",
            "   10000/  100000: 0.0054\n",
            "   20000/  100000: 0.0035\n",
            "   30000/  100000: 0.0017\n",
            "   40000/  100000: 0.0034\n",
            "   50000/  100000: 0.0016\n",
            "   60000/  100000: 0.0010\n",
            "   70000/  100000: 0.0030\n",
            "   80000/  100000: 0.0016\n",
            "   90000/  100000: 0.0006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Model Evaluation**"
      ],
      "metadata": {
        "id": "Xr2DR7o6r5tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def check_loss(split):\n",
        "    X, y = {\n",
        "    'train': (X_train, y_train),\n",
        "    'valid': (X_valid, y_valid),\n",
        "    'test': (X_test, y_test),\n",
        "    }[split]\n",
        "\n",
        "    # Perform a forward pass\n",
        "    h_pre_act = X @ W1 + b1\n",
        "    h = torch.tanh(h_pre_act)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "\n",
        "    print(split, loss.item())\n",
        "\n",
        "check_loss('train')\n",
        "check_loss('valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_PfU9KKr4JE",
        "outputId": "15b8db96-5ade-4145-d36f-0de48bdd001a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 0.0018933809476090703\n",
            "valid 0.12775571482346032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. Make predictions**"
      ],
      "metadata": {
        "id": "N2vK9lHmr-ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(split):\n",
        "    X, y = {\n",
        "    'train': (X_train, y_train),\n",
        "    'valid': (X_valid, y_valid),\n",
        "    'test': (X_test, y_test),\n",
        "    }[split]\n",
        "\n",
        "    # Perform a forward pass\n",
        "    h_pre_act = X @ W1 + b1\n",
        "    h = torch.tanh(h_pre_act)\n",
        "    logits = h @ W2 + b2\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    y_pred = probs.max(1).indices\n",
        "    y_pred_proba = probs.max(1).values\n",
        "\n",
        "    return y_pred, y_pred_proba\n",
        "\n",
        "y_test_pred, y_test_pred_proba = predict('test')"
      ],
      "metadata": {
        "id": "Cy0TKudKr8ag"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plotting the predictions"
      ],
      "metadata": {
        "id": "CZui9FTgsBUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the predictions\n",
        "ix = torch.randint(0, X_test.shape[0], (5,))\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 1))\n",
        "for ax, img, act, pred, proba in zip(axes, X_test[ix], y_test[ix], y_test_pred[ix], y_test_pred_proba[ix]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(img.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f'Actual: {act}, Predicted: {pred}\\nProba: {proba:.4f}', fontsize=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "CfkU0bpxr_7L",
        "outputId": "c8c20539-3625-4ba9-d6cb-5a35f97c6ddc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x100 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As shown in plot above, we successfully predicted 5/5 of the data."
      ],
      "metadata": {
        "id": "iCvXBDS1oRsL"
      }
    }
  ]
}