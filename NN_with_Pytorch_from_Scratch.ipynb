{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Library Loading**"
      ],
      "metadata": {
        "id": "qY2E6Qf2sgYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDwKKzYAoYa6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preparing the Dataset**"
      ],
      "metadata": {
        "id": "8ywWfRlzokIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# import dataset\n",
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# Validate\n",
        "print('X shape:', X.shape)\n",
        "print('y shape:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t9hTFmJof2_",
        "outputId": "cd60bb1b-2833-4d41-c76b-ea0849de824b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1797, 64)\n",
            "y shape: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Splitting the data into train, valid, and test set."
      ],
      "metadata": {
        "id": "XcMwyvjEovSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split train & (valid and test) --> 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    stratify=y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Split valid & test --> 50:50\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    stratify=y_test,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Validate\n",
        "print('X train shape:', X_train.shape)\n",
        "print('y train shape:', y_train.shape)\n",
        "print('X valid shape:', X_valid.shape)\n",
        "print('y valid shape:', y_valid.shape)\n",
        "print('X test shape :', X_test.shape)\n",
        "print('y test shape :', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5FmHVRhorve",
        "outputId": "d0c5d325-83f1-4ef5-f5a2-6ce33b569f3e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train shape: (1437, 64)\n",
            "y train shape: (1437,)\n",
            "X valid shape: (180, 64)\n",
            "y valid shape: (180,)\n",
            "X test shape : (180, 64)\n",
            "y test shape : (180,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to torch tensor\n",
        "X_train, y_train = torch.tensor(X_train), torch.tensor(y_train)\n",
        "X_valid, y_valid = torch.tensor(X_valid), torch.tensor(y_valid)\n",
        "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "hrq24CXgo6lp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Create a Comparison Function**\n",
        "\n",
        "- Creating a utility function to compare manual gradients to PyTorch gradients.\n",
        "- The function is to check whether the results we calculate from scratch are the same with calculation from PyTorch library."
      ],
      "metadata": {
        "id": "w8EnkSd5o9gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function for comparing gradients\n",
        "def compare_grad(element, manual_grad, torch_node):\n",
        "    \"\"\"comparing manual gradients to PyTorch gradients\"\"\"\n",
        "    # Extract gradients\n",
        "    torch_grad = torch_node.grad\n",
        "\n",
        "    # Exact comparison\n",
        "    exact = torch.all(manual_grad == torch_grad).item()\n",
        "\n",
        "    # Approximate comparison\n",
        "    apprx = torch.allclose(manual_grad, torch_grad)\n",
        "\n",
        "    # Calculate maximum different between manual and torch gradients\n",
        "    max_diff = (\n",
        "        (manual_grad-torch_grad)    # calculate the difference\n",
        "        .abs()                      # then take the absolute value\n",
        "        .max()                      # and find the maximum value of it\n",
        "        .item()\n",
        "    )\n",
        "\n",
        "    # Print\n",
        "    print(f'{element:15s} | exact: {str(exact):5s} | approximate: {str(apprx):5s} | max diff.: {max_diff}')"
      ],
      "metadata": {
        "id": "qxKlsvBdo4Ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Creating the Neural Network using PyTorch**"
      ],
      "metadata": {
        "id": "eNdwwlqNpTxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a neural network to classify the digits.\n",
        "- The architectures are\n",
        "  - Having 64 input dimensions\n",
        "  - Having 2 layers (1 hidden layer and 1 output layer)\n",
        "  - The output layer has 10 neurons (1 neuron for each digits)"
      ],
      "metadata": {
        "id": "Ff0EvguppW-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the size\n",
        "n_in = 64\n",
        "n_hidden = 24\n",
        "n_out = 10"
      ],
      "metadata": {
        "id": "VSJ7eXo3pKUU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Neural Network\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Layer 1 (The hidden layer)\n",
        "W1 = torch.randn((n_in, n_hidden),  generator=g, dtype=torch.float64) * (5/3) / (n_in**0.5)\n",
        "b1 = torch.randn(n_hidden,          generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Layer 2 (The output layer)\n",
        "W2 = torch.randn((n_hidden, n_out), generator=g, dtype=torch.float64) * 0.1\n",
        "b2 = torch.randn(n_out,             generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Get the parameters\n",
        "parameters = [W1, b1, W2, b2]\n",
        "print(sum(param.nelement() for param in parameters))\n",
        "\n",
        "# Activate the grad\n",
        "for param in parameters:\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvYhPIwWpdqU",
        "outputId": "6a569056-036c-425f-eb94-f1d0d6bada74"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a single forward pass that we want to calculate its gradients manually."
      ],
      "metadata": {
        "id": "X_d0rZ3zpyMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1_LiahYJt_Ij-zjCE1RcHCEe2jiDxUXI-\">"
      ],
      "metadata": {
        "id": "eLNFPfD9qSzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch learning\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "\n",
        "# Construct a minibatch\n",
        "mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
        "X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
        "\n",
        "# Validating data\n",
        "print('X_batch shape:', X_batch.shape)\n",
        "print('y_batch shape:', y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1i6xWzup5Bv",
        "outputId": "f424188e-3183-4eaf-91e5-f67809e3d101"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_batch shape: torch.Size([32, 64])\n",
            "y_batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing a forward pass\n",
        "\n",
        "# The first hidden layer calculation\n",
        "h_pre_act = X_batch @ W1 + b1\n",
        "\n",
        "# Performing a non-linearity calculation (activation function)\n",
        "h = torch.tanh(h_pre_act)\n",
        "\n",
        "# The second and output layer\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# Calculating loss\n",
        "counts = logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1\n",
        "probs = counts * counts_sum_inv\n",
        "log_probs = probs.log()\n",
        "loss = -log_probs[range(n), y_batch].mean()\n",
        "\n",
        "# Performing the backward pass with PyTorch\n",
        "for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "for p in [log_probs, probs, counts_sum_inv, counts_sum, counts,\n",
        "          logits, h, h_pre_act]:\n",
        "    p.retain_grad()\n",
        "\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Yu7iyNp5af",
        "outputId": "5443412d-337e-4653-b979-cb8aaa56455a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3850, dtype=torch.float64, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Performing Backpropagation for `counts`, `counts_sum`, and `counts_sum_inv`**"
      ],
      "metadata": {
        "id": "nGKs8XdduvM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find :\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts_sum_inv}}\n",
        "$$"
      ],
      "metadata": {
        "id": "9I_PBTMCvEWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1ehlVs8Ol9-VILS-ogqaOaS8NLxNIvXcT\">"
      ],
      "metadata": {
        "id": "hz7kMIHsvJpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Calculating the `counst_sum_inv`"
      ],
      "metadata": {
        "id": "4keNEgObvNA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the graph, `counts` derivative is come from `probs` and `counts_sum`\n",
        "- We can find the `counts` derivative step by step, start from the `counts_sum_inv`\n",
        "\n",
        "\n",
        "- We can use the equation :\n",
        "```\n",
        "probs = counts * counts_sum_inv\n",
        "dprobs = counts dcounts_sum_inv\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dcounts_sum_inv = counts * dprobs\n",
        "```"
      ],
      "metadata": {
        "id": "TlD-Tdw4vRBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyfTYw6LvUj7",
        "outputId": "979e8382-4725-417c-e28a-fd3d7523359d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Calculate the `counst_sum`"
      ],
      "metadata": {
        "id": "dBo_aVTivhEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Then we can find the derivative of `loss` to the `counts_sum`\n",
        "\n",
        "- We can use the equation :\n",
        "```\n",
        "counts_sum_inv = counts_sum**-1\n",
        "dcounts_sum_inv = -1 * (counts_sum)**(-2)\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dcounts_sum = counts * dcounts_sum_inv\n",
        "```"
      ],
      "metadata": {
        "id": "FZKslpZDvjyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating dcounts_sum\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMaaBu5gvoEw",
        "outputId": "48d0fab7-c819-4dcb-c18d-8dc638505062"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Calculate the `counst`"
      ],
      "metadata": {
        "id": "h7ItDorrv4As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Finally, we can calculate the derivative of `loss` to `counts`\n",
        "- Remember, there are two sources of gradient to the `counts` node, i.e. from `probs` and `counts_sum`"
      ],
      "metadata": {
        "id": "tuN94sjLv9Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "probs = counts * counts_sum_inv\n",
        "dprobs = counts_sum_inv * dcounts\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dcounts = counts_sum_inv * dprobs\n",
        "```"
      ],
      "metadata": {
        "id": "IQoZ2y6sv_Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Next, we can use the equation\n",
        "```\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "dcounts_sum = 1. * dcounts\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dcounts = 1. * dcounts_sum\n",
        "```"
      ],
      "metadata": {
        "id": "f0rXNNI7wCf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Rqx63BwGM5",
        "outputId": "25e319d2-0709-4356-e4d6-7c7be290c09c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Performing Backprop the `logits`**"
      ],
      "metadata": {
        "id": "_b82Ga3bwXh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{logits}}\n",
        "$$"
      ],
      "metadata": {
        "id": "1TZsTuwFweZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1v4FqTiXVBT0E5wkF1ZFksYpUm8nijPEQ\">"
      ],
      "metadata": {
        "id": "dPg7a3BDwhTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "counts = exp(logits)\n",
        "dcounts = exp(logits) dlogits\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dlogits = exp(logits) * dcounts\n",
        "```"
      ],
      "metadata": {
        "id": "QupbX09swjW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits = counts * dcounts\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ImbXmLwqll",
        "outputId": "63dc2a24-b20c-4bd5-e1ee-b4156cbe3f77"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Performing Backpropagation for `W2`, `b2`, and `h`**"
      ],
      "metadata": {
        "id": "UL4kGcgcqajK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here I try to find the parameters for second layer."
      ],
      "metadata": {
        "id": "XDroIYgls5h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find :\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{W2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h}}\n",
        "$$"
      ],
      "metadata": {
        "id": "8k_AYa7ZqgtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1c8c2jyWPyWQC_nqGmk2ifb-hpIWyALKN\">"
      ],
      "metadata": {
        "id": "bKgiOuKDqjgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "logits = h @ W2 + b2\n",
        "dlogits = W2 dh\n",
        "dlogits = 1 db2\n",
        "dlogits = h dW2\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dW2 = h * dlogits\n",
        "dloss/dh = W2 * dlogits\n",
        "dloss/db2 = 1 * dlogits\n",
        "```"
      ],
      "metadata": {
        "id": "DaqDoQkxqmoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In details, let :\n",
        "\n",
        "$$\n",
        "d = h \\cdot w + c\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "d_{11} & d_{12} & d_{13}\\\\\n",
        "d_{21} & d_{22} & d_{23}\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{12}\\\\\n",
        "h_{21} & h_{22}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13}\\\\\n",
        "w_{21} & w_{22} & w_{23}\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "c_{1} & c_{2} & c_{3}\\\\\n",
        "c_{1} & c_{2} & c_{3}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "d_{11} &= h_{11}w_{11} + h_{12}w_{21} + c_{1} \\\\\n",
        "d_{12} &= h_{11}w_{12} + h_{12}w_{22} + c_{2} \\\\\n",
        "d_{13} &= h_{11}w_{13} + h_{12}w_{23} + c_{3} \\\\\n",
        "d_{21} &= h_{21}w_{11} + h_{22}w_{21} + c_{1} \\\\\n",
        "d_{22} &= h_{21}w_{12} + h_{22}w_{22} + c_{2} \\\\\n",
        "d_{23} &= h_{21}w_{13} + h_{22}w_{23} + c_{3} \\\\\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "55DkwXfdqpgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So, we can find the derivative of loss with respect to model parameters."
      ],
      "metadata": {
        "id": "dRBJqjZkqvXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial L}{\\partial w_{11}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{12}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{13}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{21}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot h_{22} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{22}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot h_{22} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{23}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot h_{22}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial w_{11}} & \\cfrac{\\partial L}{\\partial w_{12}} & \\cfrac{\\partial L}{\\partial w_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{21}} & \\cfrac{\\partial L}{\\partial w_{22}} & \\cfrac{\\partial L}{\\partial w_{23}}\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{21}\\\\\n",
        "h_{12} & h_{22}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial d_{11}} & \\cfrac{\\partial L}{\\partial d_{12}} & \\cfrac{\\partial L}{\\partial d_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial d_{21}} & \\cfrac{\\partial L}{\\partial d_{22}} & \\cfrac{\\partial L}{\\partial d_{23}}\n",
        "\\end{bmatrix}\\\\\n",
        "\\cfrac{\\partial L}{\\partial W} &= h^{T} \\cdot \\cfrac{\\partial L}{\\partial d}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "wLbu5hfzqy_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With similar way, we got :\n",
        "\n",
        "$$\n",
        "\\cfrac{\\partial L}{\\partial h} = \\cfrac{\\partial L}{\\partial d} \\cdot W^{T}\n",
        "$$\n",
        "\n",
        "- For the bias :\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial L}{\\partial c_{1}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot 1.0 \\\\\n",
        "\\cfrac{\\partial L}{\\partial c_{2}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot 1.0 \\\\\n",
        "\\cfrac{\\partial L}{\\partial c_{3}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot 1.0 \\\\\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "SiXNBE91q5ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial c_{1}} & \\cfrac{\\partial L}{\\partial c_{2}} & \\cfrac{\\partial L}{\\partial c_{3}}\\\\\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "1.0 & 1.0 & 1.0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial d_{11}} & \\cfrac{\\partial L}{\\partial d_{12}} & \\cfrac{\\partial L}{\\partial d_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial d_{21}} & \\cfrac{\\partial L}{\\partial d_{22}} & \\cfrac{\\partial L}{\\partial d_{23}}\n",
        "\\end{bmatrix}\\\\\n",
        "\\cfrac{\\partial L}{\\partial c} &= \\begin{bmatrix}\n",
        "1.0 & 1.0 & 1.0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\cfrac{\\partial L}{\\partial d}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "fJizY7F5rA1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dlogits = counts * dcounts\n",
        "\n",
        "# Calculating backprop for 2nd layer\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)  # add along the columns (neurons)"
      ],
      "metadata": {
        "id": "nwyf7f7UrOb5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJb6jW-lp7yc",
        "outputId": "94a6e459-8080-4104-ed99-141e2657aee3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Performing Backpropagation for `W1` and `b1`**"
      ],
      "metadata": {
        "id": "7LrcyxNBtvhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we try to calculate the parameters in the first layer."
      ],
      "metadata": {
        "id": "PTyzxFJyt4qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{W1}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{b1}}\n",
        "$$"
      ],
      "metadata": {
        "id": "ZPz4kG5tuBPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1a3NSCtenXUFHU9Z3AA7EEG7GFt1PadMZ\">"
      ],
      "metadata": {
        "id": "a1ry-mY-uEL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation as follow :\n",
        "```\n",
        "h_pre_act = X @ W1 + b1\n",
        "dh_pre_act = X dW1\n",
        "dh_pre_act = 1 b1\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dW1 = X * dh_pre_act\n",
        "dloss/db1 = 1 * dh_pre_act\n",
        "```"
      ],
      "metadata": {
        "id": "CZrwwsItuGAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dlogits = counts * dcounts\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)\n",
        "dh_pre_act = (1 - h**2) * dh\n",
        "\n",
        "# Calculating backprop in 1st later\n",
        "dW1 = X_batch.T @ dh_pre_act\n",
        "db1 = dh_pre_act.sum(0)"
      ],
      "metadata": {
        "id": "caY-AexduIa9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)\n",
        "compare_grad('h_pre_act', dh_pre_act, h_pre_act)\n",
        "compare_grad('W1', dW1, W1)\n",
        "compare_grad('b1', db1, b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfZ3e3lCuJ5R",
        "outputId": "2ef14719-6b05-4cc3-a184-56a7ea2630e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h_pre_act       | exact: False | approximate: True  | max diff.: 4.336808689942018e-19\n",
            "W1              | exact: False | approximate: True  | max diff.: 4.163336342344337e-17\n",
            "b1              | exact: False | approximate: True  | max diff.: 1.734723475976807e-18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Backpropagation the `h_pre_act`**"
      ],
      "metadata": {
        "id": "gQjp9c-IrWCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we try to find the parameter of h before performed with activation function."
      ],
      "metadata": {
        "id": "ZRDlZJEQtJIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h_pre_act}}\n",
        "$$"
      ],
      "metadata": {
        "id": "qU_qhpt1rceE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1zaovirepV51QS0nS9lJVntb85Lf4tZQ_\">"
      ],
      "metadata": {
        "id": "StsGDSt0rfFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation :\n",
        "```\n",
        "h = tanh(h_pre_act)\n",
        "dh = (1 - tanh(h_pre_act)**2) dh_pre_act\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dh_pre_act = (1 - tanh(h_pre_act)**2) * dh\n",
        "```"
      ],
      "metadata": {
        "id": "42N80RUBrgyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dlogits = counts * dcounts\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)\n",
        "\n",
        "# Calculating backprop for pre-activation\n",
        "dh_pre_act = (1 - h**2) * dh"
      ],
      "metadata": {
        "id": "lUxG-eUjrQ0p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)\n",
        "compare_grad('h_pre_act', dh_pre_act, h_pre_act)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6d0bzahrj0U",
        "outputId": "9d0d35e2-8d83-4675-d149-237af90267f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h_pre_act       | exact: False | approximate: True  | max diff.: 4.336808689942018e-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Train with manual backpropagation**"
      ],
      "metadata": {
        "id": "-OqWe_YTrqxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First, reinitialize the weights"
      ],
      "metadata": {
        "id": "EIFUZGyVruC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Neural Network\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Layer 1 (The hidden layer)\n",
        "W1 = torch.randn((n_in, n_hidden),  generator=g, dtype=torch.float64) * (5/3) / (n_in**0.5)\n",
        "b1 = torch.randn(n_hidden,          generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Layer 2 (The output layer)\n",
        "W2 = torch.randn((n_hidden, n_out), generator=g, dtype=torch.float64) * 0.1\n",
        "b2 = torch.randn(n_out,             generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Get the parameters\n",
        "parameters = [W1, b1, W2, b2]\n",
        "print(sum(param.nelement() for param in parameters))\n",
        "\n",
        "# Activate the grad\n",
        "for param in parameters:\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhQesrqCrxN8",
        "outputId": "3fdfbb66-5ee1-4108-aede-5414e683169f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the NN model"
      ],
      "metadata": {
        "id": "7ieVTGoXrzTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 100_000\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "losses = []\n",
        "\n",
        "# We will calculate the grad manually\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Start optimizing\n",
        "    for i in range(max_steps):\n",
        "        # Construct a minibatch\n",
        "        mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
        "        X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
        "\n",
        "        # Perform the forward pass\n",
        "        h_pre_act = X_batch @ W1 + b1\n",
        "        h = torch.tanh(h_pre_act)\n",
        "        logits = h @ W2 + b2\n",
        "\n",
        "        # Calculate loss\n",
        "        counts = logits.exp()\n",
        "        counts_sum = counts.sum(1, keepdims=True)\n",
        "        counts_sum_inv = counts_sum**-1\n",
        "        probs = counts * counts_sum_inv\n",
        "        log_probs = probs.log()\n",
        "        loss = -log_probs[range(n), y_batch].mean()\n",
        "\n",
        "        # Let's do the backward pass\n",
        "        for p in parameters:\n",
        "            p.grad = None\n",
        "\n",
        "        # Let's manually calculate the gradients\n",
        "        dlog_probs = torch.zeros_like(log_probs)\n",
        "        dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "        dprobs = (1./probs) * dlog_probs\n",
        "        dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "        dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "        dcounts = counts_sum_inv * dprobs\n",
        "        dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "        dlogits = counts * dcounts\n",
        "        dW2 = h.T @ dlogits\n",
        "        dh = dlogits @ W2.T\n",
        "        db2 = dlogits.sum(0)\n",
        "        dh_pre_act = (1 - h**2) * dh\n",
        "        dW1 = X_batch.T @ dh_pre_act\n",
        "        db1 = dh_pre_act.sum(0)\n",
        "        grads = [dW1, db1, dW2, db2]  # store the grads of our model parameters\n",
        "\n",
        "        # Update the model parameters\n",
        "        lr = 0.05 if i < 50_000 else 0.001\n",
        "        for p, grad in zip(parameters, grads):\n",
        "            p.data += -lr * grad\n",
        "\n",
        "        # Track\n",
        "        if i%10000 == 0:\n",
        "            print(f'{i:8d}/{max_steps:8d}: {loss.item():.4f}')\n",
        "        losses.append(loss.log().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieb6xQLmrl6M",
        "outputId": "d7066027-055a-4c35-8934-3be9e65de84b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0/  100000: 2.3850\n",
            "   10000/  100000: 0.0054\n",
            "   20000/  100000: 0.0035\n",
            "   30000/  100000: 0.0017\n",
            "   40000/  100000: 0.0034\n",
            "   50000/  100000: 0.0016\n",
            "   60000/  100000: 0.0010\n",
            "   70000/  100000: 0.0030\n",
            "   80000/  100000: 0.0016\n",
            "   90000/  100000: 0.0006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Model Evaluation**"
      ],
      "metadata": {
        "id": "Xr2DR7o6r5tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def check_loss(split):\n",
        "    X, y = {\n",
        "    'train': (X_train, y_train),\n",
        "    'valid': (X_valid, y_valid),\n",
        "    'test': (X_test, y_test),\n",
        "    }[split]\n",
        "\n",
        "    # Perform a forward pass\n",
        "    h_pre_act = X @ W1 + b1\n",
        "    h = torch.tanh(h_pre_act)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "\n",
        "    print(split, loss.item())\n",
        "\n",
        "check_loss('train')\n",
        "check_loss('valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_PfU9KKr4JE",
        "outputId": "86dbd7ad-ebc8-4157-be34-b6427322e0ef"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 0.0018933809476090703\n",
            "valid 0.12775571482346032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. Make predictions**"
      ],
      "metadata": {
        "id": "N2vK9lHmr-ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(split):\n",
        "    X, y = {\n",
        "    'train': (X_train, y_train),\n",
        "    'valid': (X_valid, y_valid),\n",
        "    'test': (X_test, y_test),\n",
        "    }[split]\n",
        "\n",
        "    # Perform a forward pass\n",
        "    h_pre_act = X @ W1 + b1\n",
        "    h = torch.tanh(h_pre_act)\n",
        "    logits = h @ W2 + b2\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    y_pred = probs.max(1).indices\n",
        "    y_pred_proba = probs.max(1).values\n",
        "\n",
        "    return y_pred, y_pred_proba\n",
        "\n",
        "y_test_pred, y_test_pred_proba = predict('test')"
      ],
      "metadata": {
        "id": "Cy0TKudKr8ag"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plotting the predictions"
      ],
      "metadata": {
        "id": "CZui9FTgsBUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "ix = torch.randint(0, X_test.shape[0], (5,))\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 1))\n",
        "for ax, img, act, pred, proba in zip(axes, X_test[ix], y_test[ix], y_test_pred[ix], y_test_pred_proba[ix]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(img.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f'Actual: {act}, Predicted: {pred}\\nProba: {proba:.4f}', fontsize=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "CfkU0bpxr_7L",
        "outputId": "28720251-f7ee-4bca-851f-52f5a08881a3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x100 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}