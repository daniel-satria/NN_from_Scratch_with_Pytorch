{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Library Loading**"
      ],
      "metadata": {
        "id": "qY2E6Qf2sgYA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tDwKKzYAoYa6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preparing the Dataset**"
      ],
      "metadata": {
        "id": "8ywWfRlzokIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "# import dataset\n",
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# Validate\n",
        "print('X shape:', X.shape)\n",
        "print('y shape:', y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t9hTFmJof2_",
        "outputId": "e1320018-3a7f-44fb-d104-ac753f3d3f79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1797, 64)\n",
            "y shape: (1797,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Splitting the data into train, valid, and test set."
      ],
      "metadata": {
        "id": "XcMwyvjEovSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split train & (valid and test) --> 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    stratify=y,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Split valid & test --> 50:50\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(\n",
        "    X_test,\n",
        "    y_test,\n",
        "    stratify=y_test,\n",
        "    test_size=0.5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Validate\n",
        "print('X train shape:', X_train.shape)\n",
        "print('y train shape:', y_train.shape)\n",
        "print('X valid shape:', X_valid.shape)\n",
        "print('y valid shape:', y_valid.shape)\n",
        "print('X test shape :', X_test.shape)\n",
        "print('y test shape :', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5FmHVRhorve",
        "outputId": "86c836c2-c893-4a62-c118-3acea96bd01a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X train shape: (1437, 64)\n",
            "y train shape: (1437,)\n",
            "X valid shape: (180, 64)\n",
            "y valid shape: (180,)\n",
            "X test shape : (180, 64)\n",
            "y test shape : (180,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to torch tensor\n",
        "X_train, y_train = torch.tensor(X_train), torch.tensor(y_train)\n",
        "X_valid, y_valid = torch.tensor(X_valid), torch.tensor(y_valid)\n",
        "X_test, y_test = torch.tensor(X_test), torch.tensor(y_test)"
      ],
      "metadata": {
        "id": "hrq24CXgo6lp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Create a Comparison Function**\n",
        "\n",
        "- Creating a utility function to compare manual gradients to PyTorch gradients.\n",
        "- The function is to check whether the results we calculate from scratch are the same with calculation from PyTorch library."
      ],
      "metadata": {
        "id": "w8EnkSd5o9gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining function for comparing gradients\n",
        "def compare_grad(element, manual_grad, torch_node):\n",
        "    \"\"\"comparing manual gradients to PyTorch gradients\"\"\"\n",
        "    # Extract gradients\n",
        "    torch_grad = torch_node.grad\n",
        "\n",
        "    # Exact comparison\n",
        "    exact = torch.all(manual_grad == torch_grad).item()\n",
        "\n",
        "    # Approximate comparison\n",
        "    apprx = torch.allclose(manual_grad, torch_grad)\n",
        "\n",
        "    # Calculate maximum different between manual and torch gradients\n",
        "    max_diff = (\n",
        "        (manual_grad-torch_grad)    # calculate the difference\n",
        "        .abs()                      # then take the absolute value\n",
        "        .max()                      # and find the maximum value of it\n",
        "        .item()\n",
        "    )\n",
        "\n",
        "    # Print\n",
        "    print(f'{element:15s} | exact: {str(exact):5s} | approximate: {str(apprx):5s} | max diff.: {max_diff}')"
      ],
      "metadata": {
        "id": "qxKlsvBdo4Ix"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Creating the Neural Network using PyTorch**"
      ],
      "metadata": {
        "id": "eNdwwlqNpTxa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a neural network to classify the digits.\n",
        "- The architectures are\n",
        "  - Having 64 input dimensions\n",
        "  - Having 2 layers (1 hidden layer and 1 output layer)\n",
        "  - The output layer has 10 neurons (1 neuron for each digits)"
      ],
      "metadata": {
        "id": "Ff0EvguppW-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the size\n",
        "n_in = 64\n",
        "n_hidden = 24\n",
        "n_out = 10"
      ],
      "metadata": {
        "id": "VSJ7eXo3pKUU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Neural Network\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Layer 1 (The hidden layer)\n",
        "W1 = torch.randn((n_in, n_hidden),  generator=g, dtype=torch.float64) * (5/3) / (n_in**0.5)\n",
        "b1 = torch.randn(n_hidden,          generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Layer 2 (The output layer)\n",
        "W2 = torch.randn((n_hidden, n_out), generator=g, dtype=torch.float64) * 0.1\n",
        "b2 = torch.randn(n_out,             generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Get the parameters\n",
        "parameters = [W1, b1, W2, b2]\n",
        "print(sum(param.nelement() for param in parameters))\n",
        "\n",
        "# Activate the grad\n",
        "for param in parameters:\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvYhPIwWpdqU",
        "outputId": "ab6f3671-159f-49b4-902c-2b842a8d5c76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Creating a single forward pass that we want to calculate its gradients manually."
      ],
      "metadata": {
        "id": "X_d0rZ3zpyMD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1_LiahYJt_Ij-zjCE1RcHCEe2jiDxUXI-\">"
      ],
      "metadata": {
        "id": "eLNFPfD9qSzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a batch learning\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "\n",
        "# Construct a minibatch\n",
        "mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
        "X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
        "\n",
        "# Validating data\n",
        "print('X_batch shape:', X_batch.shape)\n",
        "print('y_batch shape:', y_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1i6xWzup5Bv",
        "outputId": "add614c9-c4b7-4941-95cc-259f8025f8cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_batch shape: torch.Size([32, 64])\n",
            "y_batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing a forward pass\n",
        "\n",
        "# The first hidden layer calculation\n",
        "h_pre_act = X_batch @ W1 + b1\n",
        "\n",
        "# Performing a non-linearity calculation (activation function)\n",
        "h = torch.tanh(h_pre_act)\n",
        "\n",
        "# The second and output layer\n",
        "logits = h @ W2 + b2\n",
        "\n",
        "# Calculating loss\n",
        "counts = logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1\n",
        "probs = counts * counts_sum_inv\n",
        "log_probs = probs.log()\n",
        "loss = -log_probs[range(n), y_batch].mean()\n",
        "\n",
        "# Performing the backward pass with PyTorch\n",
        "for p in parameters:\n",
        "    p.grad = None\n",
        "\n",
        "for p in [log_probs, probs, counts_sum_inv, counts_sum, counts,\n",
        "          logits, h, h_pre_act]:\n",
        "    p.retain_grad()\n",
        "\n",
        "loss.backward()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Yu7iyNp5af",
        "outputId": "8253fae2-d659-4fb8-ff36-6f61d28a0f07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3850, dtype=torch.float64, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Performing Backpropagation for `counts`, `counts_sum`, and `counts_sum_inv`**"
      ],
      "metadata": {
        "id": "nGKs8XdduvM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find :\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts_sum}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{counts_sum_inv}}\n",
        "$$"
      ],
      "metadata": {
        "id": "9I_PBTMCvEWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1ehlVs8Ol9-VILS-ogqaOaS8NLxNIvXcT\">"
      ],
      "metadata": {
        "id": "hz7kMIHsvJpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Calculating the `counst_sum_inv`"
      ],
      "metadata": {
        "id": "4keNEgObvNA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- From the graph, `counts` derivative is come from `probs` and `counts_sum`\n",
        "- We can find the `counts` derivative step by step, start from the `counts_sum_inv`\n",
        "\n",
        "\n",
        "- We can use the equation :\n",
        "```\n",
        "probs = counts * counts_sum_inv\n",
        "dprobs = counts dcounts_sum_inv\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dcounts_sum_inv = counts * dprobs\n",
        "```"
      ],
      "metadata": {
        "id": "TlD-Tdw4vRBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyfTYw6LvUj7",
        "outputId": "1e8bec51-9122-46d1-bde5-a1a9da33cd0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Calculate the `counst_sum`"
      ],
      "metadata": {
        "id": "dBo_aVTivhEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Then we can find the derivative of `loss` to the `counts_sum`\n",
        "\n",
        "- We can use the equation :\n",
        "```\n",
        "counts_sum_inv = counts_sum**-1\n",
        "dcounts_sum_inv = -1 * (counts_sum)**(-2)\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dcounts_sum = counts * dcounts_sum_inv\n",
        "```"
      ],
      "metadata": {
        "id": "FZKslpZDvjyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating dcounts_sum\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMaaBu5gvoEw",
        "outputId": "2fc89434-bbbc-46cf-913e-be69e5a101ec"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Calculate the `counst`"
      ],
      "metadata": {
        "id": "h7ItDorrv4As"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Finally, we can calculate the derivative of `loss` to `counts`\n",
        "- Remember, there are two sources of gradient to the `counts` node, i.e. from `probs` and `counts_sum`"
      ],
      "metadata": {
        "id": "tuN94sjLv9Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "probs = counts * counts_sum_inv\n",
        "dprobs = counts_sum_inv * dcounts\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dcounts = counts_sum_inv * dprobs\n",
        "```"
      ],
      "metadata": {
        "id": "IQoZ2y6sv_Cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Next, we can use the equation\n",
        "```\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "dcounts_sum = 1. * dcounts\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dcounts = 1. * dcounts_sum\n",
        "```"
      ],
      "metadata": {
        "id": "f0rXNNI7wCf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Rqx63BwGM5",
        "outputId": "969d4a38-da35-433c-d0d1-d63d96531249"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Performing Backprop the `logits`**"
      ],
      "metadata": {
        "id": "_b82Ga3bwXh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{logits}}\n",
        "$$"
      ],
      "metadata": {
        "id": "1TZsTuwFweZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1v4FqTiXVBT0E5wkF1ZFksYpUm8nijPEQ\">"
      ],
      "metadata": {
        "id": "dPg7a3BDwhTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "counts = exp(logits)\n",
        "dcounts = exp(logits) dlogits\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dlogits = exp(logits) * dcounts\n",
        "```"
      ],
      "metadata": {
        "id": "QupbX09swjW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlogits = counts * dcounts\n",
        "\n",
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ImbXmLwqll",
        "outputId": "8b9963e7-d95b-4ca9-beeb-91859a2a9f26"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Performing Backpropagation for `W2`, `b2`, and `h`**"
      ],
      "metadata": {
        "id": "UL4kGcgcqajK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here I try to find the parameters for second layer."
      ],
      "metadata": {
        "id": "XDroIYgls5h-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find :\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{W2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h2}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h}}\n",
        "$$"
      ],
      "metadata": {
        "id": "8k_AYa7ZqgtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1c8c2jyWPyWQC_nqGmk2ifb-hpIWyALKN\">"
      ],
      "metadata": {
        "id": "bKgiOuKDqjgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation\n",
        "```\n",
        "logits = h @ W2 + b2\n",
        "dlogits = W2 dh\n",
        "dlogits = 1 db2\n",
        "dlogits = h dW2\n",
        "```\n",
        "\n",
        "- Thus\n",
        "```\n",
        "dloss/dW2 = h * dlogits\n",
        "dloss/dh = W2 * dlogits\n",
        "dloss/db2 = 1 * dlogits\n",
        "```"
      ],
      "metadata": {
        "id": "DaqDoQkxqmoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In details, let :\n",
        "\n",
        "$$\n",
        "d = h \\cdot w + c\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "d_{11} & d_{12} & d_{13}\\\\\n",
        "d_{21} & d_{22} & d_{23}\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{12}\\\\\n",
        "h_{21} & h_{22}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "w_{11} & w_{12} & w_{13}\\\\\n",
        "w_{21} & w_{22} & w_{23}\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "c_{1} & c_{2} & c_{3}\\\\\n",
        "c_{1} & c_{2} & c_{3}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "d_{11} &= h_{11}w_{11} + h_{12}w_{21} + c_{1} \\\\\n",
        "d_{12} &= h_{11}w_{12} + h_{12}w_{22} + c_{2} \\\\\n",
        "d_{13} &= h_{11}w_{13} + h_{12}w_{23} + c_{3} \\\\\n",
        "d_{21} &= h_{21}w_{11} + h_{22}w_{21} + c_{1} \\\\\n",
        "d_{22} &= h_{21}w_{12} + h_{22}w_{22} + c_{2} \\\\\n",
        "d_{23} &= h_{21}w_{13} + h_{22}w_{23} + c_{3} \\\\\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "55DkwXfdqpgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So, we can find the derivative of loss with respect to model parameters."
      ],
      "metadata": {
        "id": "dRBJqjZkqvXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial L}{\\partial w_{11}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{12}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{13}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot h_{11} + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot h_{21} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{21}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot h_{22} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{22}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot h_{22} \\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{23}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot h_{12} + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot h_{22}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial w_{11}} & \\cfrac{\\partial L}{\\partial w_{12}} & \\cfrac{\\partial L}{\\partial w_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial w_{21}} & \\cfrac{\\partial L}{\\partial w_{22}} & \\cfrac{\\partial L}{\\partial w_{23}}\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "h_{11} & h_{21}\\\\\n",
        "h_{12} & h_{22}\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial d_{11}} & \\cfrac{\\partial L}{\\partial d_{12}} & \\cfrac{\\partial L}{\\partial d_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial d_{21}} & \\cfrac{\\partial L}{\\partial d_{22}} & \\cfrac{\\partial L}{\\partial d_{23}}\n",
        "\\end{bmatrix}\\\\\n",
        "\\cfrac{\\partial L}{\\partial W} &= h^{T} \\cdot \\cfrac{\\partial L}{\\partial d}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "wLbu5hfzqy_t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With similar way, we got :\n",
        "\n",
        "$$\n",
        "\\cfrac{\\partial L}{\\partial h} = \\cfrac{\\partial L}{\\partial d} \\cdot W^{T}\n",
        "$$\n",
        "\n",
        "- For the bias :\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\cfrac{\\partial L}{\\partial c_{1}} &= \\cfrac{\\partial L}{\\partial d_{11}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{21}} \\cdot 1.0 \\\\\n",
        "\\cfrac{\\partial L}{\\partial c_{2}} &= \\cfrac{\\partial L}{\\partial d_{12}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{22}} \\cdot 1.0 \\\\\n",
        "\\cfrac{\\partial L}{\\partial c_{3}} &= \\cfrac{\\partial L}{\\partial d_{13}} \\cdot 1.0 + \\cfrac{\\partial L}{\\partial d_{23}} \\cdot 1.0 \\\\\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "SiXNBE91q5ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\begin{align*}\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial c_{1}} & \\cfrac{\\partial L}{\\partial c_{2}} & \\cfrac{\\partial L}{\\partial c_{3}}\\\\\n",
        "\\end{bmatrix}\n",
        "&=\n",
        "\\begin{bmatrix}\n",
        "1.0 & 1.0 & 1.0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\begin{bmatrix}\n",
        "\\cfrac{\\partial L}{\\partial d_{11}} & \\cfrac{\\partial L}{\\partial d_{12}} & \\cfrac{\\partial L}{\\partial d_{13}}\\\\\n",
        "\\cfrac{\\partial L}{\\partial d_{21}} & \\cfrac{\\partial L}{\\partial d_{22}} & \\cfrac{\\partial L}{\\partial d_{23}}\n",
        "\\end{bmatrix}\\\\\n",
        "\\cfrac{\\partial L}{\\partial c} &= \\begin{bmatrix}\n",
        "1.0 & 1.0 & 1.0\n",
        "\\end{bmatrix}\n",
        "\\cdot\n",
        "\\cfrac{\\partial L}{\\partial d}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "metadata": {
        "id": "fJizY7F5rA1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dlogits = counts * dcounts\n",
        "\n",
        "# Write the code here\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)  # add along the columns (neurons)"
      ],
      "metadata": {
        "id": "nwyf7f7UrOb5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJb6jW-lp7yc",
        "outputId": "3f6dbdbd-4166-4939-b4ec-0ae7cc5668d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Performing Backpropagation for `W1` and `b1`**"
      ],
      "metadata": {
        "id": "7LrcyxNBtvhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we try to calculate the parameters in the first layer."
      ],
      "metadata": {
        "id": "PTyzxFJyt4qv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{W1}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{b1}}\n",
        "$$"
      ],
      "metadata": {
        "id": "ZPz4kG5tuBPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph :\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1a3NSCtenXUFHU9Z3AA7EEG7GFt1PadMZ\">"
      ],
      "metadata": {
        "id": "a1ry-mY-uEL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation as follow :\n",
        "```\n",
        "h_pre_act = X @ W1 + b1\n",
        "dh_pre_act = X dW1\n",
        "dh_pre_act = 1 b1\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dW1 = X * dh_pre_act\n",
        "dloss/db1 = 1 * dh_pre_act\n",
        "```"
      ],
      "metadata": {
        "id": "CZrwwsItuGAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dlogits = counts * dcounts\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)\n",
        "dh_pre_act = (1 - h**2) * dh\n",
        "\n",
        "# Write the code here\n",
        "dW1 = X_batch.T @ dh_pre_act\n",
        "db1 = dh_pre_act.sum(0)"
      ],
      "metadata": {
        "id": "caY-AexduIa9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)\n",
        "compare_grad('h_pre_act', dh_pre_act, h_pre_act)\n",
        "compare_grad('W1', dW1, W1)\n",
        "compare_grad('b1', db1, b1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfZ3e3lCuJ5R",
        "outputId": "7ab645dc-d23e-4a0b-8978-d42c893d8b92"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h_pre_act       | exact: False | approximate: True  | max diff.: 4.336808689942018e-19\n",
            "W1              | exact: False | approximate: True  | max diff.: 4.163336342344337e-17\n",
            "b1              | exact: False | approximate: True  | max diff.: 2.6020852139652106e-18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Backpropagation the `h_pre_act`**"
      ],
      "metadata": {
        "id": "gQjp9c-IrWCh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we try to find the parameter of h before performed with activation function."
      ],
      "metadata": {
        "id": "ZRDlZJEQtJIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We need to find\n",
        "\n",
        "$$\n",
        "\\cfrac\n",
        "{\\partial \\ \\text{loss}}\n",
        "{\\partial \\ \\text{h_pre_act}}\n",
        "$$"
      ],
      "metadata": {
        "id": "qU_qhpt1rceE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In graph\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1zaovirepV51QS0nS9lJVntb85Lf4tZQ_\">"
      ],
      "metadata": {
        "id": "StsGDSt0rfFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can use the equation :\n",
        "```\n",
        "h = tanh(h_pre_act)\n",
        "dh = (1 - tanh(h_pre_act)**2) dh_pre_act\n",
        "```\n",
        "\n",
        "- Thus :\n",
        "```\n",
        "dloss/dh_pre_act = (1 - tanh(h_pre_act)**2) * dh\n",
        "```"
      ],
      "metadata": {
        "id": "42N80RUBrgyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dlog_probs = torch.zeros_like(log_probs)\n",
        "dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "dprobs = (1./probs) * dlog_probs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "dcounts = counts_sum_inv * dprobs\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dlogits = counts * dcounts\n",
        "dW2 = h.T @ dlogits\n",
        "dh = dlogits @ W2.T\n",
        "db2 = dlogits.sum(0)\n",
        "\n",
        "# Write the code here\n",
        "dh_pre_act = (1 - h**2) * dh"
      ],
      "metadata": {
        "id": "lUxG-eUjrQ0p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the comparison between manual & automatic gradients\n",
        "compare_grad('log_probs', dlog_probs, log_probs)\n",
        "compare_grad('probs', dprobs, probs)\n",
        "compare_grad('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "compare_grad('counts_sum', dcounts_sum, counts_sum)\n",
        "compare_grad('counts', dcounts, counts)\n",
        "compare_grad('logits', dlogits, logits)\n",
        "compare_grad('W2', dW2, W2)\n",
        "compare_grad('h', dh, h)\n",
        "compare_grad('b2', db2, b2)\n",
        "compare_grad('h_pre_act', dh_pre_act, h_pre_act)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6d0bzahrj0U",
        "outputId": "ea0e09f8-6ad0-41b6-9ace-668fbae094de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_probs       | exact: True  | approximate: True  | max diff.: 0.0\n",
            "probs           | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | max diff.: 0.0\n",
            "counts          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "logits          | exact: True  | approximate: True  | max diff.: 0.0\n",
            "W2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h               | exact: True  | approximate: True  | max diff.: 0.0\n",
            "b2              | exact: True  | approximate: True  | max diff.: 0.0\n",
            "h_pre_act       | exact: False | approximate: True  | max diff.: 4.336808689942018e-19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. Train with manual backpropagation**"
      ],
      "metadata": {
        "id": "-OqWe_YTrqxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First, reinitialize the weights"
      ],
      "metadata": {
        "id": "EIFUZGyVruC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Neural Network\n",
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Layer 1 (The hidden layer)\n",
        "W1 = torch.randn((n_in, n_hidden),  generator=g, dtype=torch.float64) * (5/3) / (n_in**0.5)\n",
        "b1 = torch.randn(n_hidden,          generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Layer 2 (The output layer)\n",
        "W2 = torch.randn((n_hidden, n_out), generator=g, dtype=torch.float64) * 0.1\n",
        "b2 = torch.randn(n_out,             generator=g, dtype=torch.float64) * 0.1\n",
        "\n",
        "# Get the parameters\n",
        "parameters = [W1, b1, W2, b2]\n",
        "print(sum(param.nelement() for param in parameters))\n",
        "\n",
        "# Activate the grad\n",
        "for param in parameters:\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhQesrqCrxN8",
        "outputId": "fd049322-e1b5-4964-8cbc-7d5f38811b12"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train the NN model"
      ],
      "metadata": {
        "id": "7ieVTGoXrzTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_steps = 100_000\n",
        "batch_size = 32\n",
        "n = batch_size\n",
        "losses = []\n",
        "\n",
        "# We will calculate the grad manually\n",
        "with torch.no_grad():\n",
        "\n",
        "    # Start optimizing\n",
        "    for i in range(max_steps):\n",
        "        # Construct a minibatch\n",
        "        mini_ix = torch.randint(0, X_train.shape[0], (batch_size,), generator=g)\n",
        "        X_batch, y_batch = X_train[mini_ix], y_train[mini_ix]\n",
        "\n",
        "        # Perform the forward pass\n",
        "        h_pre_act = X_batch @ W1 + b1\n",
        "        h = torch.tanh(h_pre_act)\n",
        "        logits = h @ W2 + b2\n",
        "\n",
        "        # Calculate loss\n",
        "        counts = logits.exp()\n",
        "        counts_sum = counts.sum(1, keepdims=True)\n",
        "        counts_sum_inv = counts_sum**-1\n",
        "        probs = counts * counts_sum_inv\n",
        "        log_probs = probs.log()\n",
        "        loss = -log_probs[range(n), y_batch].mean()\n",
        "\n",
        "        # Let's do the backward pass\n",
        "        for p in parameters:\n",
        "            p.grad = None\n",
        "\n",
        "        # Let's manually calculate the gradients\n",
        "        dlog_probs = torch.zeros_like(log_probs)\n",
        "        dlog_probs[range(n), y_batch] = -1.0 / n\n",
        "        dprobs = (1./probs) * dlog_probs\n",
        "        dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
        "        dcounts_sum = -1 * (counts_sum)**(-2) * dcounts_sum_inv\n",
        "        dcounts = counts_sum_inv * dprobs\n",
        "        dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "        dlogits = counts * dcounts\n",
        "        dW2 = h.T @ dlogits\n",
        "        dh = dlogits @ W2.T\n",
        "        db2 = dlogits.sum(0)\n",
        "        dh_pre_act = (1 - h**2) * dh\n",
        "        dW1 = X_batch.T @ dh_pre_act\n",
        "        db1 = dh_pre_act.sum(0)\n",
        "        grads = [dW1, db1, dW2, db2]  # store the grads of our model parameters\n",
        "\n",
        "        # Update the model parameters\n",
        "        lr = 0.05 if i < 50_000 else 0.001\n",
        "        for p, grad in zip(parameters, grads):\n",
        "            p.data += -lr * grad\n",
        "\n",
        "        # Track\n",
        "        if i%10000 == 0:\n",
        "            print(f'{i:8d}/{max_steps:8d}: {loss.item():.4f}')\n",
        "        losses.append(loss.log().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieb6xQLmrl6M",
        "outputId": "f15cf672-1778-447d-bb10-a4d75e0e59ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       0/  100000: 2.3850\n",
            "   10000/  100000: 0.0052\n",
            "   20000/  100000: 0.0035\n",
            "   30000/  100000: 0.0017\n",
            "   40000/  100000: 0.0020\n",
            "   50000/  100000: 0.0013\n",
            "   60000/  100000: 0.0010\n",
            "   70000/  100000: 0.0028\n",
            "   80000/  100000: 0.0017\n",
            "   90000/  100000: 0.0007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11. Model Evaluation**"
      ],
      "metadata": {
        "id": "Xr2DR7o6r5tM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def check_loss(split):\n",
        "    X, y = {\n",
        "    'train': (X_train, y_train),\n",
        "    'valid': (X_valid, y_valid),\n",
        "    'test': (X_test, y_test),\n",
        "    }[split]\n",
        "\n",
        "    # Perform a forward pass\n",
        "    h_pre_act = X @ W1 + b1\n",
        "    h = torch.tanh(h_pre_act)\n",
        "    logits = h @ W2 + b2\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "\n",
        "    print(split, loss.item())\n",
        "\n",
        "check_loss('train')\n",
        "check_loss('valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_PfU9KKr4JE",
        "outputId": "51290805-a34c-4f27-fce1-0e6403a93e8b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 0.001800913632289739\n",
            "valid 0.14544663165366303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **12. Make predictions**"
      ],
      "metadata": {
        "id": "N2vK9lHmr-ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(split):\n",
        "    X, y = {\n",
        "    'train': (X_train, y_train),\n",
        "    'valid': (X_valid, y_valid),\n",
        "    'test': (X_test, y_test),\n",
        "    }[split]\n",
        "\n",
        "    # Perform a forward pass\n",
        "    h_pre_act = X @ W1 + b1\n",
        "    h = torch.tanh(h_pre_act)\n",
        "    logits = h @ W2 + b2\n",
        "    probs = F.softmax(logits, dim=1)\n",
        "    y_pred = probs.max(1).indices\n",
        "    y_pred_proba = probs.max(1).values\n",
        "\n",
        "    return y_pred, y_pred_proba\n",
        "\n",
        "y_test_pred, y_test_pred_proba = predict('test')"
      ],
      "metadata": {
        "id": "Cy0TKudKr8ag"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Plotting the predictions"
      ],
      "metadata": {
        "id": "CZui9FTgsBUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "ix = torch.randint(0, X_test.shape[0], (5,))\n",
        "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 1))\n",
        "for ax, img, act, pred, proba in zip(axes, X_test[ix], y_test[ix], y_test_pred[ix], y_test_pred_proba[ix]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(img.reshape(8, 8), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title(f'Actual: {act}, Predicted: {pred}\\nProba: {proba:.4f}', fontsize=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "CfkU0bpxr_7L",
        "outputId": "7cfa336e-58bf-47e6-b68e-60a167ff6c80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x100 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}